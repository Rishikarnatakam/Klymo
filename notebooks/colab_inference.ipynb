{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sentinel-2 Super-Resolution (4×)\n",
                "\n",
                "**Upscale Sentinel-2 imagery from 10m/pixel → 2.5m/pixel using SwinIR**\n",
                "\n",
                "- ✅ Streaming data pipeline (no full scene downloads)\n",
                "- ✅ Light fine-tuning (≤3 epochs, L1 loss only)\n",
                "- ✅ Hallucination guardrails\n",
                "\n",
                "Enable GPU: `Runtime → Change runtime type → T4 GPU`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Clone repository & install\n",
                "!git clone https://github.com/Rishikarnatakam/Klymo.git\n",
                "%cd Klymo\n",
                "!pip install -q -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Verify GPU\n",
                "import torch\n",
                "assert torch.cuda.is_available(), \"GPU not available! Enable it in Runtime settings.\"\n",
                "print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
                "DEVICE = 'cuda'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Kaggle authentication\n",
                "# Go to kaggle.com/settings → Create New API Token → copy the token shown\n",
                "import os\n",
                "import getpass\n",
                "\n",
                "kaggle_username = input(\"Enter your Kaggle username: \")\n",
                "kaggle_token = getpass.getpass(\"Enter your Kaggle API token (hidden): \")\n",
                "\n",
                "# Create kaggle.json\n",
                "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
                "with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
                "    f.write(f'{{\"username\":\"{kaggle_username}\",\"key\":\"{kaggle_token}\"}}')\n",
                "os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
                "\n",
                "print(\"✓ Kaggle authenticated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Download WorldStrat dataset (streaming compatible patches)\n",
                "# Clean up previous downloads to prevent unzip prompts\n",
                "!rm -rf datasets/worldstrat\n",
                "!kaggle datasets download -d jucor1/worldstrat -p datasets/worldstrat --unzip -o\n",
                "\n",
                "# Verify download success\n",
                "import os\n",
                "if not os.path.exists(\"datasets/worldstrat/spot\") and not os.path.exists(\"datasets/worldstrat/sentinel2\"):\n",
                "    print(\"\\n❌ DOWNLOAD FAILED / ACCESS DENIED\")\n",
                "    print(\"You likely encountered a 403 Forbidden error.\")\n",
                "    print(\"FIX: Please visit https://www.kaggle.com/datasets/jucor1/worldstrat\")\n",
                "    print(\"Click 'Download' (or 'Agree') to accept the dataset rules, then re-run this cell.\")\n",
                "else:\n",
                "    print(\"✓ Dataset ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Create streaming DataLoader\n",
                "# Loads patches one-by-one, processes, releases from memory\n",
                "from src.data.worldstrat_loader import WorldStratDataset\n",
                "from torch.utils.data import DataLoader\n",
                "from pathlib import Path\n",
                "\n",
                "train_ds = WorldStratDataset(\n",
                "    root_dir=Path('datasets/worldstrat'),\n",
                "    split='train',\n",
                "    max_samples=200  # Use subset for efficiency\n",
                ")\n",
                "\n",
                "val_ds = WorldStratDataset(\n",
                "    root_dir=Path('datasets/worldstrat'),\n",
                "    split='validation',\n",
                "    max_samples=40\n",
                ")\n",
                "\n",
                "# Streaming loader: batch_size=1 → load, train, release\n",
                "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, pin_memory=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, pin_memory=True)\n",
                "\n",
                "print(f\"✓ Train: {len(train_ds)} patches | Val: {len(val_ds)} patches\")\n",
                "print(\"Data is streamed patch-by-patch, not stored in memory\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Fine-tune SwinIR (3 epochs, L1 loss only)\n",
                "from src.training.finetune import SwinIRTrainer\n",
                "from src.models.swinir import load_swinir_model\n",
                "\n",
                "# Load pretrained model\n",
                "model = load_swinir_model(device=DEVICE)\n",
                "print(f\"✓ Loaded pretrained SwinIR (4×)\")\n",
                "\n",
                "# Create trainer with conservative settings\n",
                "trainer = SwinIRTrainer(\n",
                "    model=model,\n",
                "    device=DEVICE,\n",
                "    learning_rate=1e-5,  # Low LR for fine-tuning\n",
                "    max_epochs=3,        # Hard limit per spec\n",
                ")\n",
                "\n",
                "# Train (streaming: load patch → train → release memory)\n",
                "results = trainer.train(train_loader, val_loader)\n",
                "print(f\"\\n✓ Fine-tuning complete! Best loss: {results['best_loss']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. GEE authentication (for live tile fetching)\n",
                "from google.colab import auth\n",
                "auth.authenticate_user()\n",
                "\n",
                "import ee\n",
                "ee.Initialize(project='klymo-486313')\n",
                "print(\"✓ GEE authenticated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8. Fetch real Sentinel-2 tile (streamed via GEE API)\n",
                "from src.data.gee_fetcher import GEEFetcher\n",
                "\n",
                "fetcher = GEEFetcher(authenticate=False)\n",
                "fetcher.authenticated = True\n",
                "fetcher.ee = ee\n",
                "\n",
                "# Stream tile from Delhi, India\n",
                "delhi_tile = fetcher.fetch_tile('delhi', tile_size=256)\n",
                "print(f\"✓ Streamed tile: {delhi_tile.shape} from GEE (no local storage)\")\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "plt.figure(figsize=(6, 6))\n",
                "plt.imshow(delhi_tile)\n",
                "plt.title('Sentinel-2 Delhi (10m/pixel) - Streamed from GEE')\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 9. Run super-resolution on streamed tile\n",
                "from src.inference.pipeline import SuperResolutionPipeline\n",
                "\n",
                "pipeline = SuperResolutionPipeline(device=DEVICE)\n",
                "results = pipeline.run(delhi_tile)\n",
                "\n",
                "print(f\"Input:  {results['lr'].shape} → 10m/pixel\")\n",
                "print(f\"Output: {results['sr'].shape} → 2.5m/pixel (4× enhancement)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 10. Visualize: LR → Bicubic → SwinIR comparison\n",
                "import matplotlib.pyplot as plt\n",
                "from src.data.preprocessing import to_8bit_visualization\n",
                "from skimage.transform import resize\n",
                "\n",
                "lr = results['lr']\n",
                "bicubic = results['bicubic']\n",
                "sr = results['sr']\n",
                "\n",
                "lr_up = resize(lr, sr.shape[:2], order=0, preserve_range=True)\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
                "\n",
                "axes[0].imshow(to_8bit_visualization(lr_up))\n",
                "axes[0].set_title('Low Resolution (10m/pixel)', fontsize=14)\n",
                "axes[0].axis('off')\n",
                "\n",
                "axes[1].imshow(to_8bit_visualization(bicubic))\n",
                "axes[1].set_title('Bicubic 4× (Baseline)', fontsize=14)\n",
                "axes[1].axis('off')\n",
                "\n",
                "axes[2].imshow(to_8bit_visualization(sr))\n",
                "axes[2].set_title('SwinIR 4× (2.5m/pixel)', fontsize=14)\n",
                "axes[2].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('outputs/visualizations/comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"✓ Saved comparison to outputs/visualizations/comparison.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 11. Compute quality metrics\n",
                "from src.metrics.psnr import compute_psnr\n",
                "from src.metrics.ssim import compute_ssim\n",
                "\n",
                "psnr = compute_psnr(bicubic, sr)\n",
                "ssim = compute_ssim(bicubic, sr)\n",
                "\n",
                "print(\"=\"*40)\n",
                "print(\"Quality Metrics (SwinIR vs Bicubic)\")\n",
                "print(\"=\"*40)\n",
                "print(f\"  PSNR: {psnr:.2f} dB\")\n",
                "print(f\"  SSIM: {ssim:.4f}\")\n",
                "print(\"=\"*40)\n",
                "\n",
                "# Show hallucination check results\n",
                "if 'checks' in results:\n",
                "    print(\"\\nHallucination Checks:\")\n",
                "    for name, check in results['checks']['checks'].items():\n",
                "        status = \"✓\" if check['passed'] else \"✗\"\n",
                "        print(f\"  {status} {name}: {check['score']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 12. Download results\n",
                "from google.colab import files\n",
                "files.download('outputs/visualizations/comparison.png')\n",
                "print(\"✓ Download started!\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}